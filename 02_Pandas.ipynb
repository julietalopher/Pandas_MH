{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Python para Ciencia de Datos: Pandas**\n",
    "\n",
    "___\n",
    "\n",
    "**Saúl Arciniega Esparza** | Ph.D. Profesor Asociado C Tiempo Completo\n",
    "\n",
    "* [Twitter](https://twitter.com/zaul_arciniega) | [LinkedIn](https://www.linkedin.com/in/saularciniegaesparza/) | [ResearchGate](https://www.researchgate.net/profile/Saul-Arciniega-Esparza)\n",
    "* [Hydrogeology Group](https://www.ingenieria.unam.mx/hydrogeology/), [Facultad de Ingeniería de la UNAM](https://www.ingenieria.unam.mx/)\n",
    "___\n",
    "\n",
    "### **Contenido**\n",
    "\n",
    "0. [Introducción a Pandas](#Introducción-a-Pandas)\n",
    "1. [Pandas Series](#1.-Pandas-Series)\n",
    "    1. [Creación de Series](#1.1-Creación-de-Series)\n",
    "    2. [Series desde archivos delimitados](#1.2-Series-desde-archivos-delimitados)\n",
    "    3. [Llamando elementos de una Serie](#1.3-Llamando-elementos-de-una-Serie)\n",
    "    4. [Remplazar elementos de una Serie](#1.4-Remplazar-elementos-de-una-Serie)\n",
    "    5. [Agregar elementos a una Serie](#1.5-Agregar-elementos-a-una-Serie)\n",
    "    6. [Estadísticos de una Serie](#1.6-Estadísticos-de-una-Serie)\n",
    "    7. [Operaciones algebráicas](#1.7-Operaciones-algebráicas)\n",
    "2. [Pandas DataFrames](#2.-Pandas-DataFrames)\n",
    "    1. [Creación de DataFrames](#2.1-Crear-un-DataFrame-manualmente)\n",
    "    2. [Crear un DataFrame a partir de Series](#2.2-Crear-un-DataFrame-a-partir-de-varias-Series)\n",
    "    3. [Trabajar con NaNs](#2.3-Trabajar-con-valores-NaN)\n",
    "    4. [DataFrames desde archivos delimitados](#2.4-DataFrames-desde-archivos-delimitados)\n",
    "    5. [Manipulación de fechas](#2.5-Trabajar-con-fechas)\n",
    "    6. [Renombrar columnas e índices](#2.6-Renombrar-columnas-y-cambiar-indices)\n",
    "    7. [Llamar renglones y columnas](#2.7-Llamar-renglones-y-columnas)\n",
    "    8. [Llamar renglones con fechas](#2.8-Llamar-renglones-con-fechas)\n",
    "    9. [Condicionales](#2.9-Condicionales)\n",
    "    10. [Estadísticos de DataFrames](#2.10-Estadisticos-de-DataFrames)\n",
    "    11. [Operaciones algebráicas](#2.11-Operaciones-algebráicas-con-DataFrames)\n",
    "3. [Agrupaciones](#3.-Agrupaciones)\n",
    "    1. [Agregaciones de series temporales](#3.1-Agregaciones-de-series-temporales)\n",
    "4. [Exportar y leer archivos delimitados](#4.-Exportar-y-leer-archivos-delimitados)\n",
    "5. [Operaciones de DataFrames con Series](#5.-Operaciones-de-DataFrames-con-Series)\n",
    "    1. [Trabajar con arrays](#5.1-Trabajar-con-arrays)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Introducción a Pandas\n",
    "\n",
    "[Ir a Inicio](#Contenido)\n",
    "\n",
    "[**Pandas**](https://pandas.pydata.org/) es una librería de python destinada al análisis de datos, que proporciona unas estructuras de datos flexibles y que permiten trabajar con ellos de forma muy eficiente. Pandas ofrece las siguientes estructuras de datos:\n",
    "\n",
    "- **Series**: Son arrays unidimensionales con indexación (arrays con índice o etiquetados), similar a los diccionarios. Pueden generarse a partir de diccionarios o de listas.\n",
    "     \n",
    "- **DataFrame**: Son estructuras de datos similares a las tablas de bases de datos relacionales como SQL.\n",
    "\n",
    "La forma convencional de importar la librería de Pandas es mediante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importaremos algunas librerías adicionales\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# 1. Pandas Series\n",
    "\n",
    "[Ir a inicio](#Contenido)\n",
    "\n",
    "El primer ejemplo que vamos a poner va a ser el de definir una estructura de datos \"Series\" que como ya comentamos es un array de datos unidimensional con idexación.\n",
    "\n",
    "## 1.1 Creación de Series\n",
    "\n",
    "Las \"Series\" se definen de la siguiente manera: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.rand(6)\n",
    "index = [1, 2, 3, 4, 5, 6]\n",
    "\n",
    "serie = pd.Series(data, index=index)\n",
    "serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El primer parámetro le indicamos los datos del array y en el segundo parámetro los índices.\n",
    "También podemos definir índices y valores como texto, o datos mixtos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.random.rand(6)\n",
    "index = ['a', 'b', 'c', 'd', 'e', 'f']\n",
    "\n",
    "serie = pd.Series(data, index=index)\n",
    "serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando no especificamos el parámetro de índice, se crea una numeración desde cero al número de elementos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = np.random.rand(6)\n",
    "\n",
    "serie = pd.Series(data)\n",
    "serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos crear una serie desde un diccionario de forma muy sencilla:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'a':1, 'b':3, 'c': 4, 'd':2}\n",
    "serie = pd.Series(data)\n",
    "serie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Series desde archivos delimitados\n",
    "\n",
    "Frecuentemente nos veremos en la necesidad de trabajar con series de tiempo almacenadas en archivos, en donde lo más común (y recomendado) es utilizar archivos de texto plano delimitados por comas (csv) o por tabuladores (txt).\n",
    "\n",
    "Para leer una serie almecenada en alguno de estos formatos podemos utilizar el comando **pd.read_csv**.\n",
    "\n",
    "Aqui podemos tener dos escenarios:\n",
    "\n",
    "1. **Serie SIN una primera línea de encabezados**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "serie1 = pd.read_csv(\n",
    "    './Datos/Serie_sin_encabezado.csv', # nombre del archivo \n",
    "    sep=',',                           # delimitación de columnas\n",
    "    index_col=[0],                     # qué columna usaremos de índice\n",
    "    header=None,  # indicamos que no hay una primera línea de encabezado\n",
    ")\n",
    "serie1 = serie1.squeeze()  # necesario para cargarlo como serie\n",
    "\n",
    "serie1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Serie CON una primera línea de encabezados**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie2 = pd.read_csv(\n",
    "    './Datos/Serie_con_encabezado.csv', # nombre del archivo \n",
    "    sep=',',                           # delimitación de columnas\n",
    "    index_col=[0],                     # qué columna usaremos de índice\n",
    ")\n",
    "serie2 = serie2.squeeze()  # necesario para cargarlo como serie\n",
    "\n",
    "serie2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Llamando elementos de una Serie\n",
    "\n",
    "A diferencia de los otros objetos en Python que utilizan **[]** para llamar a algún un elemento, los objetos de pandas utilizan dos métodos: **.iloc[]** y **.loc[]**:\n",
    "\n",
    "- **.iloc**: se utiliza para llamar a algún elemento a partir de su índice numérico (que va de cero al número de elementos menos uno).\n",
    "- **.loc**: se utiliza para llamar a algún elemento a partir del índice que establece el usuario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamando elementos con .iloc\n",
    "print(serie1.iloc[0])   # llamar al primer elemento\n",
    "print(serie1.iloc[-1])  # llamar al ultimo elemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamando elementos con .loc\n",
    "print(serie1.loc[1981])   # llamar al primer elemento\n",
    "print(serie1.loc[2017])  # llamar al ultimo elemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLamar un rango de elementos\n",
    "print(serie1.iloc[1:4])\n",
    "print(serie1.loc[1982:1984])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Remplazar elementos de una Serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver los primeros 5 elementos de la serie\n",
    "serie1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reemplazar usando el indice de la Serie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie1.loc[1981] = 100\n",
    "serie1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reemplazar usando la posición del elemento dentro de la serie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "serie1.iloc[0] = 1700\n",
    "serie1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Agregar elementos a una Serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar los 5 últimos elementos de una serie\n",
    "serie1.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos agregar los elementos utilizando **.loc** o **.iloc**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "serie1.loc[2018] = 1500\n",
    "serie1.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O también sólo utilizando corchetes **[nuevo indice]**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "serie1[2019] = 1000\n",
    "serie1.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Estadísticos de una Serie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Leer una serie desde un archivo csv\n",
    "df = pd.read_csv(\n",
    "    './Datos/Serie_sin_encabezado.csv', # nombre del archivo \n",
    "    sep=',',                           # delimitación de columnas\n",
    "    index_col=[0],                     # qué columna usaremos de índice\n",
    "    header=None,  # indicamos que no hay una primera línea de encabezado\n",
    ")\n",
    "df = df.squeeze()  # necesario para cargarlo como serie\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Estadisticos descriptivos\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Estadisticos\n",
    "print('mean: ', df.mean())\n",
    "print('std : ', df.std())\n",
    "print('min : ', df.min())\n",
    "print('25% : ', df.quantile(0.25))\n",
    "print('50% : ', df.median())\n",
    "print('25% : ', df.quantile(0.75))\n",
    "print('max : ', df.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# asimetria y kurtosis\n",
    "print('asimetria: ', df.skew())\n",
    "print('kurtosis : ', df.kurtosis())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Suma acumulada\n",
    "df_acum = df.cumsum()\n",
    "df_acum.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Operaciones algebráicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.read_csv('./Datos/serie1.csv', sep=',', index_col=[0], header=None).squeeze()\n",
    "s2 = pd.read_csv('./Datos/serie2.csv', sep=',', index_col=[0], header=None).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 + s2      # suma de dos series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 / s2      # división de dos series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "s1 ** 0.5    # elevar las series a una potencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1.corr(s2)  # correlacion de la serie 1 con la serie 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como remover los nans de una serie\n",
    "s3 = s2 - s1 \n",
    "s3.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# 2. Pandas DataFrames\n",
    "\n",
    "[Ir a Inicio](#Contenido)\n",
    "\n",
    "Los Dataframes se componen de múltiples Series y comparten muchos métodos en común, pero existen algunos dedicados exclusivamente a los DataFrames.\n",
    "\n",
    "Para crear un DataFrame debemos indicar los datos de entrada, el índice y las columnas:\n",
    "\n",
    "## 2.1 Crear un DataFrame manualmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.rand(6, 2)\n",
    "index = [1, 2, 3, 4, 5, 6]\n",
    "columns = ['A', 'B']\n",
    "\n",
    "df = pd.DataFrame(data, index=index, columns=columns)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()  # obtener informacion de las columnas del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3) # regresa los primeros tres renglones del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail(2)  # regresa los ultimos tres renglones del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generar un dataframe a partir de un diccionario\n",
    "data = {'a':[1.6, 5.6], 'b':[3.5, 6.3], 'c': [4.1, 2.8], 'd':[2.8, 5], 'e': [8.0, 3.0]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generar un dataframe a partir de un diccionario\n",
    "data = {'a':[1.6, 5.6], 'b':[3.5, 6.3], 'c': [4.1, 2.8], 'd':[2.8, 5], 'e': [8.0, 3.0]}\n",
    "df = pd.DataFrame(data).transpose()   # Transpuesta de tabla\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Crear un DataFrame a partir de varias Series\n",
    "\n",
    "Un DataFrame puede ser creado a partir de series existentes, para ello existen distintas funciones para combinar las series, una de las más sencillas de utilizar es **pd.concat**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.read_csv('./Datos/serie1.csv', sep=',', index_col=[0], header=None).squeeze()\n",
    "s2 = pd.read_csv('./Datos/serie2.csv', sep=',', index_col=[0], header=None).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat((s1, s2))  # une dos series en la misma columna\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat((s1, s2), axis=1)  # une dos series en diferentes columnas\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Trabajar con valores NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = pd.read_csv('./Datos/serie1.csv', sep=',', index_col=[0], header=None).squeeze()\n",
    "s2 = pd.read_csv('./Datos/serie2.csv', sep=',', index_col=[0], header=None).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remover NaNs\n",
    "df = pd.concat((s1, s2), axis=1)\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rellenar NaNs\n",
    "df = pd.concat((s1, s2), axis=1)\n",
    "df = df.fillna(0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 DataFrames desde archivos delimitados\n",
    "\n",
    "La función **pd.read_csv** también permite leer tablas con múltiples columnas y convertirlas a DataFrames:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Datos/Precipitacion_mm-d.csv', index_col=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Trabajar con fechas\n",
    "\n",
    "Cuando trabajamos con tablas que contienen fechas debemos realizar una serie de transformaciones ya que por defecto, las celdas con fechas dentro de un archivo delimitado son interpretadas como texto.\n",
    "\n",
    "Por ejemplo, el siguiente caso tratamos de importar una serie de datos diarios, en donde la primer columna corresponde a la fecha:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Datos/Precipitacion_mm-d.csv', index_col=[0])\n",
    "df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si quisieramos utilizar el índice como si fuera una fecha **nos arrojará un error** ya que se trata de un string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.year   # tratar de obtener el año del indice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo más fácil en este caso es convertir la primer columna a un formato de fechas desde que se importa la información, para ello se ingresa el parametro opcional **parse_dates**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Datos/Precipitacion_mm-d.csv', index_col=[0], parse_dates=[0])\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.year   # obtener el año"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.month   # obtener el mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.index.day   # obtener el dia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Renombrar columnas y cambiar indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos los datos sin indicar la columna de indice\n",
    "df = pd.read_csv('./Datos/Precipitacion_mm-d.csv', parse_dates=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renombrar columnas. Se debe ingresar el mismo numero de elementos segun el numerod de columnas\n",
    "df.columns = [\"Fecha\", \"Serie1\", \"Serie2\", \"Serie3\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignar una columa como indice\n",
    "df = df.set_index(\"Fecha\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir indice a columna\n",
    "df = df.reset_index()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar una nueva columna con un valor constante\n",
    "df[\"Factor\"] = 0.5\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregar una nueva columna con diferentes valores\n",
    "df[\"K\"] = df[\"Serie1\"] + df[\"Serie2\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Llamar renglones y columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Datos/DataFrame1.csv', index_col=[0], sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Llamar la primer columna de precipitacion directamente\n",
    "df[\"Prec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamar la primer columna de usando punto **.**\n",
    "df.Prec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Llamar a la primer columa\n",
    "df.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamar a la primer columa\n",
    "df.loc[:, \"Prec\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamar todas las columnas del 2000 al 2005\n",
    "df.loc[2000:2005, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Llamar AET del 2001 al 2009\n",
    "df.loc[2001:2009, \"AET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Crear nueva columna a partir de otras columnas\n",
    "df[\"EI\"] = df[\"AET\"] / df[\"Prec\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamar multiples columnas\n",
    "df.loc[2000:2005, [\"Prec\", \"EI\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 Llamar renglones con fechas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Datos/Precipitacion_mm-d.csv', index_col=[0], parse_dates=[0])\n",
    "df.columns = [\"Serie1\", \"Serie2\", \"Serie3\"]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Llamar todas las columnas para un conjunto de fechas\n",
    "df.loc[\"1981-01-01\":\"1981-01-10\", :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Llamar una columna para un conjunto de fechas\n",
    "df.loc[\"1981-01-01\":\"1981-01-10\", \"Serie1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Llamar varias columnas para un conjunto de fechas\n",
    "df.loc[\"1981-01-01\":\"1981-01-10\", [\"Serie3\", \"Serie1\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9 Condicionales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Datos/DataFrame1.csv', sep=',', index_col=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# condicionales simples\n",
    "mask = df[\"Prec\"] > df[\"Prec\"].mean()\n",
    "df.loc[mask, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = df[\"Prec\"] >= df[\"Prec\"].mean()\n",
    "mask2 = df[\"AET\"] >= df[\"AET\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# multiples condicionales\n",
    "mask1 = df[\"Prec\"] >= df[\"Prec\"].mean()\n",
    "mask2 = df[\"AET\"] >= df[\"AET\"].mean()\n",
    "df.loc[mask1 | mask2, :]  # mask1 o mask2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# usar condicionales para clasificar datos\n",
    "df[\"Clima\"] = \"Seco\"\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask = df[\"Prec\"] >= df[\"Prec\"].mean()\n",
    "df.loc[mask, \"Clima\"] = \"Humedo\"\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.10 Estadisticos de DataFrames\n",
    "\n",
    "Los estadísticos para DtafRames se pueden aplicar por columnas (por defecto) o por renglones. En todos los casos, pandas omite los nans a la hora de calcular estadísticos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Datos/DataFrame1.csv', sep=',', index_col=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Media de todas las columas\n",
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desviacion estandar de todas las columas\n",
    "df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Media de todas las columas\n",
    "df.loc[2000:2005, :].mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Media de todas los renglones\n",
    "df.loc[2000:2005, :].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlacion entre todos las columnas\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar elementos no nans\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.11 Operaciones algebráicas con DataFrames\n",
    "\n",
    "Los DataFrames nos permiten realizar operaciones algebráicas con múltiples columnas de forma muy sencilla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Datos/DataFrame1.csv', sep=',', index_col=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = df * 0.9\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sumar dos DataFrames\n",
    "(df1 + df).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debemos de tener cuidado cuando intentamos realizar operaciones entre una serie y un DataFrame\n",
    "(df1.loc[:, \"Prec\"] + df).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(df1.mean() + df).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cuando un DataFrame no contiene todos lon índices del otro,\n",
    "# las operaciones se realizan en los índices en común\n",
    "df1 + df.loc[2000:2010, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# 3. Agrupaciones\n",
    "\n",
    "[Ir a Inicio](#Contenido)\n",
    "\n",
    "Las agrupaciones en pandas funcionan como las tablas dinámicas en Excel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./Datos/DataFrame1.csv', index_col=[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask = df[\"Prec\"] >= df[\"Prec\"].mean()\n",
    "df[\"Clima\"] = \"Seco\"\n",
    "df.loc[mask, \"Clima\"] = \"Humedo\"\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generar grupo poor tipo de clima\n",
    "grupo = df.groupby(\"Clima\")\n",
    "grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Estadisticos por tipo de clima\n",
    "grupo.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estadisticos por tipo de clima (un poco ordenado)\n",
    "grupo.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calcular la media de cada grupo\n",
    "grupo.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# calcular múltiples estadísticos\n",
    "grupo.agg(['mean', 'std']).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Agregaciones de series temporales\n",
    "\n",
    "Las agrupaciones con **groupby** son muy útiles cuando tenemos tablas categorizadas, pero qué pasa cuando tenemos series temporales y queremos cambiar de escala temporal, digamos de escala diaria a mensual o de mensual a anual?\n",
    "\n",
    "Para ello usamos el método **.resample**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar un DataFrame delimitado por comas\n",
    "prec = pd.read_csv('./Datos/Precipitacion_mm-d.csv', index_col=[0], parse_dates=[0])\n",
    "prec.columns = [\"Serie1\", \"Serie2\", \"Serie3\"]\n",
    "prec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregacion mensual\n",
    "prec.resample(\"1M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resample sólo realiza agrupaciones, necesitamos indicacar una función estadística a realizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregacion de suma mensual\n",
    "prec.resample(\"1M\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregacion de promedio mensual\n",
    "prec.resample(\"1M\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agregacion suma cada dos meses\n",
    "prec.resample(\"2M\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Agregacion de suma anual\n",
    "prec.resample(\"1Y\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# 4. Exportar y leer archivos delimitados\n",
    "\n",
    "[Ir a Inicio](#Contenido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importar un DataFrame delimitado por comas\n",
    "prec = pd.read_csv('./Datos/Precipitacion_mm-d.csv', delimiter=',', index_col=[0], parse_dates=[0])\n",
    "prec.columns = [\"Serie1\", \"Serie2\", \"Serie3\"]\n",
    "prec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Realizar la suma anual de precipitacion\n",
    "prec_anual = prec.groupby(prec.index.year).sum()\n",
    "prec_anual.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar tabla\n",
    "prec_anual.to_csv(\"export1.csv\")              # Exportar delimitado por comas\n",
    "prec_anual.to_csv(\"export2.csv\", index=False) # Exportar delimitado por comas sin el indice\n",
    "prec_anual.to_csv(\"export3.txt\", sep=\"\\t\")    # Exportar delimitado por tabulador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# 5. Operaciones de DataFrames con Series\n",
    "\n",
    "[Ir a Inicio](#Contenido)\n",
    "\n",
    "Se pueden realizar operaciones en DataFrames con Series, en este caso, las Series se toman como un escalar que se utilizará para efectuar alguna operación algebráica para cada columna del DataFrame. en este caso, los índices de la Serie deben de coincidir con las columnas del DataFrame.\n",
    "\n",
    "Para este ejemplo multiplicaremos el area de la cuenca por la precipitación annual acumulada para sacar el volumen de agua por cuenca en hectómetros cúbicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cuencas = pd.read_csv('./Datos/Propiedades_cuencas.txt', delimiter='\\t')\n",
    "cuencas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero generamos una serie con las areas de las cuencas\n",
    "# En este caso, los indices deben de ser definidos por la columna ID\n",
    "# Además, extraemos las areas solo de las cuencas 1 a 3\n",
    "area = cuencas.set_index(\"ID\").loc[1:3, \"Area\"]\n",
    "area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Antes de hacer la operacion debemos verificar que los indices de la Serie y las columnas del DataFrame sean del mismo tipo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(area.index)\n",
    "print(prec_anual.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que los indices de la Serie son enteros mientras que las columnas del DataFrame son objetos (texto).\n",
    "Debemos convertir alguno de ellos para poder realizar una operación directa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# igualamos el tipo de elementos en columnas e indices\n",
    "area.index = [\"Serie1\", \"Serie2\", \"Serie3\"]\n",
    "area.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora realizamos la operacion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prec_anual_hm3 = (prec_anual / 1000) * (area * 1e6) / 1e6\n",
    "# (prec_anual / 1000)  convertir precipitation de mm a m\n",
    "# (area * 1e6) convertir area de km2 a m2\n",
    "# / 1e6     convertir de m3 a Hm3\n",
    "prec_anual_hm3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Trabajar con arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar un DataFrame delimitado por comas\n",
    "prec = pd.read_csv('./Datos/Precipitacion_mm-d.csv', delimiter=',', index_col=[0], parse_dates=[0])\n",
    "prec.columns = [\"Serie1\", \"Serie2\", \"Serie3\"]\n",
    "prec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer valores de una tabla como array\n",
    "prec.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extraer la primer columna del array\n",
    "prec.values[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraer la primer columna como array\n",
    "prec.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
